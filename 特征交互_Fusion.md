# 二、Fusion
融合不同的多模态信息，与bridge相比，融合更关注项目之间的多模态内部关系。  
它可以灵活地融合不同权重和焦点的多模态信息。  
注意机制是应用最为广泛的特征融合。
## 2.1 粗粒度注意力。
一些模型应用注意力机制在粗粒度级别融合来自多种模式的信息。  
### 注：将多模态信息分为用户侧和项目侧，包括各自的id信息和side信息：UVCAN、MCPTR。  
### UVCAN: User-Video Co-Attention Network for Personalized Micro-video Recommendation 2019
UVCAN将多模态信息分为用户侧和物品侧，包括各自的id信息和side信息。它利用用户侧的多模态数据，通过自注意力生成项目侧的融合权重。  
![image](https://github.com/NanGongNingYi/-/assets/61775768/cb0033f3-14a5-4cd8-bc0d-7e57bad42769)
协同过滤的插图通过三步推理堆叠了注意力网络框架来探索用户对微视频特征的关注。 

### MCPTR: Multi-Modal Contrastive Pre-training for Recommendation 2022
MCPTR建议并行合并项目和用户信息。  
方法包含两个过程：预训练和微调。  
**在预训练阶段**，我们提出了一种基于辅助信息和隐式反馈矩阵 R 的多模态对比表示模型。具体来说，我们提出的预训练模型包含两个组成部分：用户建模和项目建模。  
**在用户建模部分**，我们首先使用文本编码器来获取每个评论文本的表示，然后使用模内聚合来获取用户的评论嵌入。接下来，应用图编码器来捕获齐次图 Gu 的结构信息。对于这两种不同的模态信息，我们开发了模态间聚合以获得用户的多模态表示。  
**在项目建模中**，我们利用文本编码器、图像编码器和图编码器对每个项目的描述文本、图像和齐次图 Gi 进行编码。然后，我们应用模间聚合来获得项目的多模态表示。此外，由于对于同一项目，描述文本和图像信息是互补的，因此它们具有相似的语义。我们开发了一种自我监督的对比学习方法来调整它们之间的表示。  
最后，采用基于反馈矩阵R的二元交叉熵损失函数来捕获目标用户u与其对应的目标项目i的潜在相关性。**在微调过程中**，现有的推荐模型利用预先训练的用户/项目嵌入作为初始化，并仅基于反馈矩阵 R 微调这些嵌入。  
![image](https://github.com/NanGongNingYi/-/assets/61775768/d1deaaab-da29-486e-8ab0-8b3e60508da9)

### 注：CMBF、MML、MCPTR、HCGCN引入交叉注意力机制来分别共同学习图像和文本模态的语义信息。  
### CMBF: Cross-Modal-Based Fusion Recommendation Algorithm 2021
CMBF引入交叉注意力机制来分别共同学习图像和文本模态的语义信息，然后将它们连接起来。  
现有的多模态推荐算法都是提取单一模态的特征并简单拼接不同模态的特征来预测推荐结果。这种融合方法不能完全挖掘多模态特征的相关性，丢失了不同模态之间的关系，影响了预测结果。  
在本文中，我们提出了一种基于跨模态的融合推荐算法（CMBF），该算法可以捕获单模态特征和跨模态特征。我们的算法使用一种新颖的跨模态融合方法来完全融合多模态特征并学习不同模态之间的交叉信息。  
![image](https://github.com/NanGongNingYi/-/assets/61775768/7fbfe257-1887-42de-bdd8-26c9d011a1d3)  
基于CMBF的拟议框架概述。图像/文本特征学习层和跨模态融合层的详细信息分别如图2和图3所示。  
![image](https://github.com/NanGongNingYi/-/assets/61775768/8507b835-fd00-4f0c-b1c4-63570b8a37d6)  
特征学习层的图示。(a)代表图像特征学习层，(b)代表文本特征学习层。  
![image](https://github.com/NanGongNingYi/-/assets/61775768/8e74386a-66c5-4ff9-924c-b3d875b47b5e)  
跨模式融合层的图示。  

### MML: Multimodal Meta-Learning for Cold-Start Sequential Recommendation 2022
MML基于id信息设计了一个注意力层，并辅以视觉和文本信息。  
在MAML框架下，我们提出的MML将多模态信息（即相关的文本和图像数据）作为一种辅助信息纳入元学习过程中，以减少任务发散并提高跨任务知识迁移的有效性。具体来说，我们在两个方面利用项目的多模态信息。  
**首先**，为了尽量减少新老用户顺序特征的差异，我们精心设计了一组对应三种不同模态（即ID、文本和图像）的多模态元学习器，这可以通过参考彼此的预测来稳定和改进元训练过程。  
**其次**，考虑到新项目的特征差异，我们设计了一个冷启动项目嵌入生成器，它利用多模态信息来预热新项目的 ID 嵌入。 MML的整体架构如图1(a)所示。  
为了快速适应数据不足的冷启动用户，我们将MAML扩展到我们的场景，并设计一个三阶段算法来训练元学习器、嵌入生成器和依次预测融合层如图1(b)所示。**文章详细介绍了训练算法。**  
![image](https://github.com/NanGongNingYi/-/assets/61775768/58390983-049c-498f-95cd-fadcd99c6786)  


### MCPTR: 

### HCGCN: 

