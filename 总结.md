### MMGCN: Multi-modal Graph Convolution Network for Personalized Recommendation of Micro-video

MMGCN为每种模态建立了一个用户-项目二分图。对于每个节点，可以利用相邻节点的拓扑结构和项目的模态信息来更新该节点的特征表达。
<img src="https://github.com/NanGongNingYi/-/assets/61775768/bcb8cce8-f1a3-408d-a856-4c8de5bfbc22" width="70%">

### Graph-Refined Convolutional Network for Multimedia Recommendation with Implicit Feedback

潜在的挑战在于交互图的质量，因为观察到的与不太感兴趣的项目的交互发生在隐式反馈中（例如，用户意外观看微视频）。这意味着涉及此类假阳性边缘的邻域将产生负面影响，并且用户偏好的信号可能会受到严重污染。

<img src="https://github.com/NanGongNingYi/-/assets/61775768/66603506-894c-47e2-97ca-14e40362f036" width="70%">
<img src="https://github.com/NanGongNingYi/-/assets/61775768/7ddc3d0a-c147-41ec-816e-52a710733e1b" width="70%">
该模型由三个组件组成：1）图细化层，通过识别和修剪交互图中的噪声边来调整图结构； 2）图卷积层，对精化图进行图卷积运算，以丰富项目和用户的嵌入； 3）预测层，用于推断每个用户和项目对的交互。



<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
<img src="" width="70%">
